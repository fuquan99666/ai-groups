import requests
from bs4 import BeautifulSoup
from urllib.parse import quote

def get_weather_func(location: str) -> str:
    """
    è·å–æŒ‡å®šåœ°ç‚¹çš„ä¸“ä¸šå¤©æ°”ä¿¡æ¯
    å‚æ•°:
        location (str): åœ°ç‚¹åç§°ï¼Œå¦‚"å±±ä¸œçƒŸå°"
    è¿”å›:
        str: æ ¼å¼åŒ–åçš„ä¸“ä¸šå¤©æ°”ä¿¡æ¯
    """
    # é…ç½®è¯·æ±‚å¤´ï¼ˆæ¨¡æ‹Ÿæµè§ˆå™¨ï¼‰
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36",
        "Accept-Language": "zh-CN,zh;q=0.9",
    }
    
    try:
        # Step 1. å‘èµ·ç™¾åº¦æœç´¢è¯·æ±‚
        query = f"{location} å¤©æ°”"
        url = f"https://www.baidu.com/s?wd={quote(query)}"
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        # Step 2. è§£æHTML
        soup = BeautifulSoup(response.text, 'html.parser')
        
        def safe_extract(element, selector, attribute="text"):
            found = element.select_one(selector)
            if not found: return "N/A"
            return found.get_text().strip() if attribute == "text" else found.get(attribute, "N/A")
        
        # å®šä½ä¸“ä¸šå¤©æ°”æŒ‡æ•°åŒºåŸŸ
        profession_section = soup.select_one(".profession_5Z1LF.pc_Al2N0")
        if not profession_section:
            return f"æœªæ‰¾åˆ°{location}çš„ä¸“ä¸šå¤©æ°”æŒ‡æ•°å¡ç‰‡ï¼Œè¯·æ£€æŸ¥åŸå¸‚åæˆ–é¡µé¢ç»“æ„æ˜¯å¦å˜åŒ–"
        
        # æå–ä¸“ä¸šå¤©æ°”æŒ‡æ•°æ•°æ®
        indices_data = {
            "feels_like": {
                "value": safe_extract(profession_section, ".box-item_4dDrB .content-num_mjUkj"),
                "description": safe_extract(profession_section, ".box-item_4dDrB rich-text span", "text")
            },
            "uv_index": {
                "level": safe_extract(profession_section, ".contentbox_1D4Mz.no-num_iJQjL .content-text_3tR6g"),
                "description": safe_extract(profession_section, ".contentbox_1D4Mz.no-num_iJQjL + rich-text span", "text")
            },
            "humidity": {
                "value": safe_extract(profession_section, ".contentbox_1D4Mz .content-num_mjUkj:nth-of-type(1)"),
                "description": safe_extract(profession_section, ".contentbox_1D4Mz + rich-text span", "text")
            },
            "precipitation": {
                "value": safe_extract(profession_section, "div.box-item_4dDrB:has(> div:contains('é™æ°´é‡')) .content-num_mjUkj") + "æ¯«ç±³",
                "description": safe_extract(profession_section, "div.box-item_4dDrB:has(> div:contains('é™æ°´é‡')) + rich-text span", "text")
            }
        }
        
        # æå–æ—¥å‡ºæ—¥è½ä¿¡æ¯
        sun_data = {
            "sunrise": safe_extract(profession_section, ".time-box_7HzyG .time_3p7ft.num_3De1N"),
            "sunset": safe_extract(profession_section, ".right-text_5FdgQ .time_3p7ft.num_3De1N")
        }
        
        # Step 4. ç»„ç»‡è¾“å‡ºæ ¼å¼
        output = [
            f"{location} ä¸“ä¸šå¤©æ°”æŒ‡æ•°æŠ¥å‘Š",
            "----------------------------",
            f"ğŸŒ¡ï¸ ä½“æ„Ÿæ¸©åº¦: {indices_data['feels_like']['value']} ({indices_data['feels_like']['description']})",
            f"â˜€ï¸ ç´«å¤–çº¿æŒ‡æ•°: {indices_data['uv_index']['level']} ({indices_data['uv_index']['description']})",
            f"ğŸ’¦ æ¹¿åº¦: {indices_data['humidity']['value']} ({indices_data['humidity']['description']})",
            f"ğŸŒ§ï¸ é™æ°´é‡: {indices_data['precipitation']['value']} ({indices_data['precipitation']['description']})",
            f"ğŸŒ… æ—¥å‡ºæ—¶é—´: {sun_data['sunrise']}",
            f"ğŸŒ‡ æ—¥è½æ—¶é—´: {sun_data['sunset']}"
        ]
        
        return "\n".join(output)
        
    except Exception as e:
        return f"å¤©æ°”æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}"